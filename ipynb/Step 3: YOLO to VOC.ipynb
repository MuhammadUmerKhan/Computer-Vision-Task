{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ **Plan for Conversion**\n",
    "1. **Create new folders** inside `train`, `test`, and `val`:  \n",
    "   - `train/annotations/`  \n",
    "   - `val/annotations/`  \n",
    "   - `test/annotations/`  \n",
    "   - These will store `.xml` (Pascal VOC) or `.json` (COCO) files.\n",
    "\n",
    "2. **Write a script to convert YOLO to Pascal VOC XML**  \n",
    "   - Read YOLO `.txt` files and extract bounding boxes.  \n",
    "   - Convert to XML format with image size information.  \n",
    "   - Save in the `annotations/` folder.\n",
    "\n",
    "3. **(Alternative) Write a script to convert YOLO to COCO JSON**  \n",
    "   - Read YOLO `.txt` files and extract bounding boxes.  \n",
    "   - Store data in COCO JSON format.  \n",
    "   - Save in the `annotations/` folder.\n",
    "\n",
    "---\n",
    "\n",
    "### üìå **Which format do you prefer?**  \n",
    "- **Pascal VOC (`.xml`)** (Recommended for Faster R-CNN in TensorFlow)  \n",
    "- **COCO (`.json`)** (If you want to try EfficientDet later)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert YOLO `.txt` annotations to Pascal VOC `.xml` format, follow these steps:\n",
    "\n",
    "### **1Ô∏è‚É£ Create a Folder Structure**\n",
    "- Inside each dataset split (`train`, `val`, `test`), create a new folder for XML annotations.\n",
    "  ```\n",
    "  /train\n",
    "    /images\n",
    "    /labels\n",
    "    /xml_annotations\n",
    "  /val\n",
    "    /images\n",
    "    /labels\n",
    "    /xml_annotations\n",
    "  /test\n",
    "    /images\n",
    "    /labels\n",
    "    /xml_annotations\n",
    "  ```\n",
    "\n",
    "### **2Ô∏è‚É£ Convert YOLO `.txt` to Pascal VOC `.xml`**\n",
    "You'll need:\n",
    "- Image dimensions (width, height)\n",
    "- Class mapping (for your case, class `0` is \"Building\")\n",
    "\n",
    "### **3Ô∏è‚É£ Python Script for Conversion**\n",
    "The script will:\n",
    "- Read `.txt` files\n",
    "- Convert YOLO format (relative `x_center, y_center, width, height`) to Pascal VOC format (absolute `xmin, ymin, xmax, ymax`)\n",
    "- Save `.xml` files in the respective `xml_annotations` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Import Libraries**\n",
    "\n",
    "**Purpose:** Import necessary libraries for:\n",
    "- `os`: For handling file system paths and directory operations.\n",
    "- `cv2`: For reading images and manipulating image data.\n",
    "- `matplotlib.pyplot as plt`: For visualizing images and annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from YOLO class IDs to human-readable class names\n",
    "class_mapping = {0: \"Building\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory paths for labels and images\n",
    "label_dir = \"../Data/tiny_object_detection_yolo/filtered_labels\"\n",
    "image_dir = \"../Data/tiny_object_detection_yolo/filtered_images\"\n",
    "\n",
    "# Subfolders representing different splits of the dataset\n",
    "sub_folders = [\"train\", \"test\", \"val\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2:** Define the yolo_to_voc function \n",
    "- to convert bounding box coordinates from YOLO format to VOC format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_to_voc(yolo_bbox, img_width, img_height):\n",
    "    \"\"\"\n",
    "    Convert YOLO format bounding box to VOC format (xmin, ymin, xmax, ymax).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Parse YOLO bounding box values (class_id, x_center, y_center, width, height)\n",
    "        class_id, x_center, y_center, width, height = map(float, yolo_bbox)\n",
    "    except ValueError:\n",
    "        # Skip invalid annotation lines\n",
    "        print(f\"Skipping invalid annotation: {yolo_bbox}\")\n",
    "        return None\n",
    "\n",
    "    # Convert normalized YOLO coordinates to absolute pixel values\n",
    "    x_center, y_center, width, height = (\n",
    "        x_center * img_width,\n",
    "        y_center * img_height,\n",
    "        width * img_width,\n",
    "        height * img_height,\n",
    "    )\n",
    "\n",
    "    # Calculate bounding box corners\n",
    "    xmin = int(x_center - width / 2)\n",
    "    ymin = int(y_center - height / 2)\n",
    "    xmax = int(x_center + width / 2)\n",
    "    ymax = int(y_center + height / 2)\n",
    "\n",
    "    return class_id, xmin, ymin, xmax, ymax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3:** Loop through each dataset \n",
    "- Split (train, test, val), read YOLO annotations, convert them to VOC format, and save them as text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Conversion completed for train set. YOLO annotations moved to ../Data/tiny_object_detection_yolo/filtered_labels/train/txt\n",
      "‚úÖ Conversion completed for test set. YOLO annotations moved to ../Data/tiny_object_detection_yolo/filtered_labels/test/txt\n",
      "‚úÖ Conversion completed for val set. YOLO annotations moved to ../Data/tiny_object_detection_yolo/filtered_labels/val/txt\n"
     ]
    }
   ],
   "source": [
    "for split in sub_folders:\n",
    "    # Define paths for labels, images, and output folder\n",
    "    labels_path = os.path.join(label_dir, split)\n",
    "    images_path = os.path.join(image_dir, split)\n",
    "    txt_output_path = os.path.join(labels_path, \"txt\")\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(txt_output_path, exist_ok=True)\n",
    "\n",
    "    for label_file in os.listdir(labels_path):\n",
    "        if label_file.endswith(\".txt\"):  # Process only .txt annotation files\n",
    "            image_file = label_file.replace(\".txt\", \".png\")\n",
    "            image_path = os.path.join(images_path, image_file)\n",
    "\n",
    "            # Check for different image file extensions (PNG, JPG, JPEG)\n",
    "            if not os.path.exists(image_path):\n",
    "                image_file = label_file.replace(\".txt\", \".jpg\")\n",
    "                image_path = os.path.join(images_path, image_file)\n",
    "\n",
    "            if not os.path.exists(image_path):\n",
    "                image_file = label_file.replace(\".txt\", \".jpeg\")\n",
    "                image_path = os.path.join(images_path, image_file)\n",
    "\n",
    "            label_path = os.path.join(labels_path, label_file)\n",
    "\n",
    "            if os.path.exists(image_path):  # Ensure image file exists\n",
    "                img = cv2.imread(image_path)  # Load image to get dimensions\n",
    "                img_height, img_width, _ = img.shape\n",
    "\n",
    "                with open(label_path, \"r\") as f:\n",
    "                    lines = f.readlines()  # Read all lines from annotation file\n",
    "\n",
    "                bboxes = []  # List to store converted bounding boxes\n",
    "                for line in lines:\n",
    "                    yolo_bbox = line.strip().split()  # Split annotation line into values\n",
    "                    converted_bbox = yolo_to_voc(yolo_bbox, img_width, img_height)  # Convert YOLO to VOC\n",
    "                    if converted_bbox:\n",
    "                        bboxes.append(converted_bbox)\n",
    "\n",
    "                # Move processed label file to output directory\n",
    "                shutil.move(label_path, os.path.join(txt_output_path, label_file))\n",
    "\n",
    "    print(f\"‚úÖ Conversion completed for {split} set. YOLO annotations moved to {txt_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4:** Combine Files\n",
    "- For each dataset split (`train`, `test`, `val`):\n",
    "- Ensures the presence of image and label directories.\n",
    "- Moves matching images and labels to the `combined_dir` while maintaining structure.\n",
    "- Issues warnings for missing label-image pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_files(image_dir, label_dir, combined_dir):\n",
    "    \"\"\"\n",
    "    Combine images and corresponding YOLO txt labels into a single directory structure.\n",
    "    \"\"\"\n",
    "    for folder in ['train', 'test', 'val']:\n",
    "        # Define paths for images and labels\n",
    "        folder_image_dir = os.path.join(image_dir, folder)\n",
    "        folder_label_dir_txt = os.path.join(label_dir, folder, 'txt')\n",
    "        combined_folder = os.path.join(combined_dir, folder)\n",
    "\n",
    "        # Create combined folder if it doesn't exist\n",
    "        os.makedirs(combined_folder, exist_ok=True)\n",
    "\n",
    "        # Ensure required folders exist\n",
    "        if not os.path.exists(folder_image_dir) or not os.path.exists(folder_label_dir_txt):\n",
    "            print(f\"Error: Missing folder structure for {folder}\")\n",
    "            continue\n",
    "\n",
    "        # Get list of image and label files\n",
    "        image_files = [f for f in os.listdir(folder_image_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        label_files_txt = [f for f in os.listdir(folder_label_dir_txt) if f.endswith('.txt')]\n",
    "\n",
    "        for image_file in image_files:\n",
    "            # Find corresponding annotation file\n",
    "            label_file_txt = image_file.replace(image_file.split('.')[-1], 'txt')\n",
    "            if label_file_txt in label_files_txt:\n",
    "                # Copy image and label to the combined directory\n",
    "                shutil.copy(os.path.join(folder_image_dir, image_file), os.path.join(combined_folder, image_file))\n",
    "                shutil.copy(os.path.join(folder_label_dir_txt, label_file_txt), os.path.join(combined_folder, label_file_txt))\n",
    "            else:\n",
    "                print(f\"Warning: No label found for {image_file} in {folder}\")\n",
    "        \n",
    "        print(f\"All files copied successfully to {folder}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Define directory paths\n",
    "    image_dir = '../Data/tiny_object_detection_yolo/filtered_images'\n",
    "    label_dir = '../Data/tiny_object_detection_yolo/filtered_labels'\n",
    "    combined_dir = '../Data/tiny_object_detection_yolo/Yolo__Data'\n",
    "    \n",
    "    # Combine images and labels into a single dataset\n",
    "    combine_files(image_dir, label_dir, combined_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5:** 3. Execution Flow:\n",
    "- The script first converts YOLO annotations to VOC format and moves them into organized directories.\n",
    "- Then, the `combine_files` function merges images and labels into a structured dataset for training.\n",
    "- The script is executed via the `main()` function, which defines necessary directory paths and triggers dataset organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files copied successfully to train.\n",
      "All files copied successfully to test.\n",
      "All files copied successfully to val.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Summary of the Process:**\n",
    "\n",
    "- 1Ô∏è‚É£. **YOLO to VOC Conversion**: It converts object detection annotations from YOLO format (which uses normalized bounding boxes) to VOC format (which uses pixel-based bounding boxes). The conversion includes creating Pascal VOC XML files for each image that contain class labels and bounding box coordinates.\n",
    "\n",
    "- 2Ô∏è‚É£. **Processing Dataset**: The script processes annotation files in different dataset splits (`train`, `test`, `val`). For each image, it reads the YOLO annotations, converts them to VOC format, and saves them as text files in an output directory.\n",
    "\n",
    "- 3Ô∏è‚É£.  **File Organization**: The `combine_files` function moves and organizes image and annotation files into a single folder structure (`train`, `test`, `val`) for each split, simplifying dataset usage.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_3_12_7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
